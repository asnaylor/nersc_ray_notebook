{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d7a456f-525b-47b8-9cb2-786f08356bd9",
   "metadata": {},
   "source": [
    "# NERSC Cluster Deploy Tutorial: Tuning Hyperparameters of a Distributed PyTorch Model with PBT using Ray Train & Tune\n",
    "\n",
    "ðŸ“– [Back to Table of Contents](../README.md)<br>\n",
    "<!-- â¬… [Previous notebook](./ex_01_pytorch_ray_hvd.ipynb) <br> -->\n",
    "âž¡ [Next notebook](./ex_02_tensorflow_ray_train_tune.ipynb) <br>\n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "We are going to run an example Ray Train & Tune code. This example looks at tunning hyperparameters of a distrbuted PyTorch Model with PBT. This tutorial is following the code in this example: https://docs.ray.io/en/latest/train/examples/pytorch/tune_cifar_torch_pbt_example.html\n",
    "\n",
    "> **Note**:\n",
    "> To setup the environment for the notebook, execute on command line: `./setup.sh 1` then select the kernel `pytorch-1.13.1` in the notebook\n",
    "\n",
    "This Ray cluster will be setup using the NERSC PyTorch module and deployed on Perlmutter.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a43fb792-f1fe-477f-bcab-a7c40000100d",
   "metadata": {},
   "source": [
    "# Starting Ray Cluster\n",
    "\n",
    "## Superfacility API\n",
    "\n",
    "To deploy the Ray cluster via the NERSC Superfacility API you require a valid API client. \n",
    "\n",
    "To create a valid client visit your profile page in [Iris](https://iris.nersc.gov/):\n",
    "\n",
    "<img src=\"img/iris_profile_header.png\" width=\"800\" />\n",
    "\n",
    "Then scroll down to the **Superfacility API Clients** section and click the \"+ New Client\" button which will produce this window:\n",
    "\n",
    "<img src=\"img/new_sf_api_client.png\" width=\"400\" />\n",
    "\n",
    "To submit and deploy a Ray cluster we require the highest security level (<span style=\"color:red\">RED</span>). **[This client id is valid for 2 days]**\n",
    "\n",
    "Once created then saved the `client_id` string and `private_key` dictionary (you can also save the private key in PEM format) ready for use with the `SuperfacilityAPI` library.\n",
    "\n",
    "> **Note**:\n",
    "> This step should only be repeated if your client has expired\n",
    "\n",
    "\n",
    "For more information about the NERSC Superfacility API visit the [documenation](https://docs.nersc.gov/services/sfapi/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f241fafb-ca37-413f-af00-d570152da2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SuperfacilityAPI import SuperfacilityAPI, SuperfacilityAccessToken\n",
    "from utility import load_secrets\n",
    "\n",
    "# Replace with your client id string and private key dictionary\n",
    "client_id, private_key = load_secrets()\n",
    "# client_id = \"<your client id string>\"\n",
    "# private_key = \"<your private key dict>\"\n",
    "\n",
    "api_key = SuperfacilityAccessToken(\n",
    "    client_id = client_id,\n",
    "    private_key = private_key\n",
    ")\n",
    "sfp_api = SuperfacilityAPI(api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5c4628-5f17-497b-b117-2a0d5eb19628",
   "metadata": {},
   "source": [
    "## Creating Ray Cluster\n",
    "\n",
    "To create a ray cluster on NERSC compute nodes, execute the `deploy_ray_cluster` function with your desired slurm sbatch options."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33863403-98c3-480c-a536-0010a7c7631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nersc_cluster_deploy import deploy_ray_cluster\n",
    "from utility import user_account\n",
    "\n",
    "slurm_options = {\n",
    "    'qos': 'debug',\n",
    "    'account': user_account(),\n",
    "    'nodes': '2',\n",
    "    't': '00:30:00'\n",
    "}\n",
    "site = 'perlmutter'\n",
    "module_load = 'pytorch/1.13.1'\n",
    "\n",
    "job = deploy_ray_cluster(\n",
    "    sfp_api,\n",
    "    slurm_options,\n",
    "    site,\n",
    "    job_setup = [f'module load {module_load}']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28830171-b8d7-420d-886d-cb08e70bb0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'error': None, 'jobid': '5906466', 'task_id': '11931'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829dfbcf-3390-440b-a5d9-58424d8c57e3",
   "metadata": {},
   "source": [
    "Now the job has been submitted, check on the job status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f1aa6f9-569f-40b4-bfff-673b7d7180ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>tres_per_node</th>\n",
       "      <th>min_cpus</th>\n",
       "      <th>min_tmp_disk</th>\n",
       "      <th>end_time</th>\n",
       "      <th>features</th>\n",
       "      <th>group</th>\n",
       "      <th>over_subscribe</th>\n",
       "      <th>jobid</th>\n",
       "      <th>name</th>\n",
       "      <th>...</th>\n",
       "      <th>partition</th>\n",
       "      <th>nodelist(reason)</th>\n",
       "      <th>start_time</th>\n",
       "      <th>state</th>\n",
       "      <th>uid</th>\n",
       "      <th>submit_time</th>\n",
       "      <th>licenses</th>\n",
       "      <th>core_spec</th>\n",
       "      <th>schednodes</th>\n",
       "      <th>work_dir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dasrepo_g</td>\n",
       "      <td>N/A</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-03-03T19:45:32</td>\n",
       "      <td>gpu&amp;a100&amp;hbm40g</td>\n",
       "      <td>75235</td>\n",
       "      <td>NO</td>\n",
       "      <td>5906466</td>\n",
       "      <td>sbatch</td>\n",
       "      <td>...</td>\n",
       "      <td>gpu_ss11</td>\n",
       "      <td>nid[003044-003045]</td>\n",
       "      <td>2023-03-03T19:15:32</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>75235</td>\n",
       "      <td>2023-03-03T19:15:32</td>\n",
       "      <td>u2:1</td>\n",
       "      <td>N/A</td>\n",
       "      <td>(null)</td>\n",
       "      <td>/global/u2/a/asnaylor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     account tres_per_node min_cpus min_tmp_disk             end_time  \\\n",
       "0  dasrepo_g           N/A      128            0  2023-03-03T19:45:32   \n",
       "\n",
       "          features  group over_subscribe    jobid    name  ... partition  \\\n",
       "0  gpu&a100&hbm40g  75235             NO  5906466  sbatch  ...  gpu_ss11   \n",
       "\n",
       "     nodelist(reason)           start_time    state    uid  \\\n",
       "0  nid[003044-003045]  2023-03-03T19:15:32  RUNNING  75235   \n",
       "\n",
       "           submit_time licenses core_spec schednodes               work_dir  \n",
       "0  2023-03-03T19:15:32     u2:1       N/A     (null)  /global/u2/a/asnaylor  \n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "sqs_table = sfp_api.get_jobs(site=site, user=os.getlogin(), sacct=False)\n",
    "sqs_df = pd.DataFrame(sqs_table['output'])\n",
    "sqs_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e6d744-9a09-4653-aa0e-39838914f975",
   "metadata": {},
   "source": [
    "Check job log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ef05bb3-7243-4ad4-9986-724d9d805311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: This is an experimental release of NCCL with an OFI plugin for use with libfabric on Perlmutter.\n",
      "In case of issues, please refer to our known issues: https://docs.nersc.gov/current/\n",
      "and open a help ticket if your issue is not listed: https://help.nersc.gov/\n",
      "[slurm] - Starting ray HEAD\n",
      "2023-03-03 19:15:38,460\tINFO usage_lib.py:435 -- Usage stats collection is disabled.\n",
      "2023-03-03 19:15:38,460\tINFO scripts.py:710 -- \u001b[37mLocal node IP\u001b[39m: \u001b[1mnid003044\u001b[22m\n",
      "2023-03-03 19:15:40,974\tSUCC scripts.py:747 -- \u001b[32m--------------------\u001b[39m\n",
      "2023-03-03 19:15:40,974\tSUCC scripts.py:748 -- \u001b[32mRay runtime started.\u001b[39m\n",
      "2023-03-03 19:15:40,974\tSUCC scripts.py:749 -- \u001b[32m--------------------\u001b[39m\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:751 -- \u001b[36mNext steps\u001b[39m\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:752 -- To connect to this Ray runtime from another node, run\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:755 -- \u001b[1m  ray start --address='nid003044:6379'\u001b[22m\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:771 -- Alternatively, use the following Python code:\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:773 -- \u001b[35mimport\u001b[39m\u001b[26m ray\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:777 -- ray\u001b[35m.\u001b[39m\u001b[26minit(address\u001b[35m=\u001b[39m\u001b[26m\u001b[33m'auto'\u001b[39m\u001b[26m, _node_ip_address\u001b[35m=\u001b[39m\u001b[26m\u001b[33m'nid003044'\u001b[39m\u001b[26m)\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:790 -- To see the status of the cluster, use\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:791 --   \u001b[1mray status\u001b[22m\u001b[26m\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:794 -- To monitor and debug Ray, view the dashboard at \n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:795 --   \u001b[1m127.0.0.1:8265\u001b[22m\u001b[26m\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:801 -- \u001b[4mIf connection fails, check your firewall settings and network configuration.\u001b[24m\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:809 -- To terminate the Ray runtime, run\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:810 -- \u001b[1m  ray stop\u001b[22m\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:888 -- \u001b[36m\u001b[1m--block\u001b[22m\u001b[39m\n",
      "2023-03-03 19:15:40,974\tINFO scripts.py:889 -- This command will now block forever until terminated by a signal.\n",
      "2023-03-03 19:15:40,975\tINFO scripts.py:892 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n",
      "[slurm] - Starting 1 ray worker nodes\n",
      "    - 1 at nid003045\n",
      "[2023-03-03 19:16:09,059 I 97729 97729] global_state_accessor.cc:356: This node has an IP address of 10.249.19.154, while we can not find the matched Raylet address. This maybe come from when you connect the Ray cluster with a different IP address or connect a container.\n",
      "2023-03-03 19:16:08,871\tINFO scripts.py:866 -- \u001b[37mLocal node IP\u001b[39m: \u001b[1m10.249.19.154\u001b[22m\n",
      "2023-03-03 19:16:09,060\tSUCC scripts.py:878 -- \u001b[32m--------------------\u001b[39m\n",
      "2023-03-03 19:16:09,060\tSUCC scripts.py:879 -- \u001b[32mRay runtime started.\u001b[39m\n",
      "2023-03-03 19:16:09,060\tSUCC scripts.py:880 -- \u001b[32m--------------------\u001b[39m\n",
      "2023-03-03 19:16:09,060\tINFO scripts.py:882 -- To terminate the Ray runtime, run\n",
      "2023-03-03 19:16:09,060\tINFO scripts.py:883 -- \u001b[1m  ray stop\u001b[22m\n",
      "2023-03-03 19:16:09,060\tINFO scripts.py:888 -- \u001b[36m\u001b[1m--block\u001b[22m\u001b[39m\n",
      "2023-03-03 19:16:09,060\tINFO scripts.py:889 -- This command will now block forever until terminated by a signal.\n",
      "2023-03-03 19:16:09,060\tINFO scripts.py:892 -- Running subprocesses are monitored and a message will be printed if any of them terminate unexpectedly. Subprocesses exit with SIGTERM will be treated as graceful, thus NOT reported.\n"
     ]
    }
   ],
   "source": [
    "!cat ~/slurm-{job['jobid']}.out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44774f49-6bd2-4232-a0fa-01214eb38956",
   "metadata": {},
   "source": [
    "## Connect to Ray Cluster\n",
    "\n",
    "Get the Ray cluster head node ip address to connect to the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ebe5b1a1-1abd-46b6-8526-a3a3602f8405",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"margin-left: 50px;display: flex;flex-direction: row;align-items: center\">\n",
       "        <h3 style=\"color: var(--jp-ui-font-color0)\">Ray</h3>\n",
       "        <svg version=\"1.1\" id=\"ray\" width=\"3em\" viewBox=\"0 0 144.5 144.6\" style=\"margin-left: 3em;margin-right: 3em\">\n",
       "            <g id=\"layer-1\">\n",
       "                <path fill=\"#00a2e9\" class=\"st0\" d=\"M97.3,77.2c-3.8-1.1-6.2,0.9-8.3,5.1c-3.5,6.8-9.9,9.9-17.4,9.6S58,88.1,54.8,81.2c-1.4-3-3-4-6.3-4.1\n",
       "                    c-5.6-0.1-9.9,0.1-13.1,6.4c-3.8,7.6-13.6,10.2-21.8,7.6C5.2,88.4-0.4,80.5,0,71.7c0.1-8.4,5.7-15.8,13.8-18.2\n",
       "                    c8.4-2.6,17.5,0.7,22.3,8c1.3,1.9,1.3,5.2,3.6,5.6c3.9,0.6,8,0.2,12,0.2c1.8,0,1.9-1.6,2.4-2.8c3.5-7.8,9.7-11.8,18-11.9\n",
       "                    c8.2-0.1,14.4,3.9,17.8,11.4c1.3,2.8,2.9,3.6,5.7,3.3c1-0.1,2,0.1,3,0c2.8-0.5,6.4,1.7,8.1-2.7s-2.3-5.5-4.1-7.5\n",
       "                    c-5.1-5.7-10.9-10.8-16.1-16.3C84,38,81.9,37.1,78,38.3C66.7,42,56.2,35.7,53,24.1C50.3,14,57.3,2.8,67.7,0.5\n",
       "                    C78.4-2,89,4.7,91.5,15.3c0.1,0.3,0.1,0.5,0.2,0.8c0.7,3.4,0.7,6.9-0.8,9.8c-1.7,3.2-0.8,5,1.5,7.2c6.7,6.5,13.3,13,19.8,19.7\n",
       "                    c1.8,1.8,3,2.1,5.5,1.2c9.1-3.4,17.9-0.6,23.4,7c4.8,6.9,4.6,16.1-0.4,22.9c-5.4,7.2-14.2,9.9-23.1,6.5c-2.3-0.9-3.5-0.6-5.1,1.1\n",
       "                    c-6.7,6.9-13.6,13.7-20.5,20.4c-1.8,1.8-2.5,3.2-1.4,5.9c3.5,8.7,0.3,18.6-7.7,23.6c-7.9,5-18.2,3.8-24.8-2.9\n",
       "                    c-6.4-6.4-7.4-16.2-2.5-24.3c4.9-7.8,14.5-11,23.1-7.8c3,1.1,4.7,0.5,6.9-1.7C91.7,98.4,98,92.3,104.2,86c1.6-1.6,4.1-2.7,2.6-6.2\n",
       "                    c-1.4-3.3-3.8-2.5-6.2-2.6C99.8,77.2,98.9,77.2,97.3,77.2z M72.1,29.7c5.5,0.1,9.9-4.3,10-9.8c0-0.1,0-0.2,0-0.3\n",
       "                    C81.8,14,77,9.8,71.5,10.2c-5,0.3-9,4.2-9.3,9.2c-0.2,5.5,4,10.1,9.5,10.3C71.8,29.7,72,29.7,72.1,29.7z M72.3,62.3\n",
       "                    c-5.4-0.1-9.9,4.2-10.1,9.7c0,0.2,0,0.3,0,0.5c0.2,5.4,4.5,9.7,9.9,10c5.1,0.1,9.9-4.7,10.1-9.8c0.2-5.5-4-10-9.5-10.3\n",
       "                    C72.6,62.3,72.4,62.3,72.3,62.3z M115,72.5c0.1,5.4,4.5,9.7,9.8,9.9c5.6-0.2,10-4.8,10-10.4c-0.2-5.4-4.6-9.7-10-9.7\n",
       "                    c-5.3-0.1-9.8,4.2-9.9,9.5C115,72.1,115,72.3,115,72.5z M19.5,62.3c-5.4,0.1-9.8,4.4-10,9.8c-0.1,5.1,5.2,10.4,10.2,10.3\n",
       "                    c5.6-0.2,10-4.9,9.8-10.5c-0.1-5.4-4.5-9.7-9.9-9.6C19.6,62.3,19.5,62.3,19.5,62.3z M71.8,134.6c5.9,0.2,10.3-3.9,10.4-9.6\n",
       "                    c0.5-5.5-3.6-10.4-9.1-10.8c-5.5-0.5-10.4,3.6-10.8,9.1c0,0.5,0,0.9,0,1.4c-0.2,5.3,4,9.8,9.3,10\n",
       "                    C71.6,134.6,71.7,134.6,71.8,134.6z\"/>\n",
       "            </g>\n",
       "        </svg>\n",
       "        <table>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Python version:</b></td>\n",
       "                <td style=\"text-align: left\"><b>3.9.15</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left\"><b>Ray version:</b></td>\n",
       "                <td style=\"text-align: left\"><b> 2.3.0</b></td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "    <td style=\"text-align: left\"><b>Dashboard:</b></td>\n",
       "    <td style=\"text-align: left\"><b><a href=\"http://127.0.0.1:8265\" target=\"_blank\">http://127.0.0.1:8265</a></b></td>\n",
       "</tr>\n",
       "\n",
       "        </table>\n",
       "    </div>\n",
       "</div>\n"
      ],
      "text/plain": [
       "ClientContext(dashboard_url='127.0.0.1:8265', python_version='3.9.15', ray_version='2.3.0', ray_commit='cf7a56b4b0b648c324722df7c99c168e92ff0b45', protocol_version='2022-12-06', _num_clients=1, _context_to_restore=<ray.util.client._ClientContext object at 0x147b1484adc0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nersc_cluster_deploy import get_ray_cluster_address\n",
    "import ray\n",
    "\n",
    "cluster_address = get_ray_cluster_address(\n",
    "    sfp_api,\n",
    "    job['jobid'],\n",
    "    site\n",
    ")\n",
    "ray.init(cluster_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400a32a4-59ab-4537-8e61-82d8aad0083f",
   "metadata": {},
   "source": [
    "Check all nodes connected to cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "67e99956-79cb-4f02-af58-ba48fd8c9557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Summary\n",
      "---------------\n",
      "Nodes: 2\n",
      "CPU:   256\n",
      "GPU:   8\n",
      "RAM:   309.42 GB\n"
     ]
    }
   ],
   "source": [
    "from nersc_cluster_deploy import ray_cluster_summary\n",
    "\n",
    "ray_cluster_summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34d1f9e-29df-4362-b8a3-9819f8966d41",
   "metadata": {},
   "source": [
    "## Setup PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b8aa28c4-6ae2-4b43-86aa-8d72ad57f753",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from filelock import FileLock\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import ray\n",
    "import ray.train as train\n",
    "from ray import tune\n",
    "from ray.air import session\n",
    "from ray.air.checkpoint import Checkpoint\n",
    "from ray.air.config import FailureConfig, RunConfig, ScalingConfig\n",
    "from ray.train.torch import TorchTrainer\n",
    "from ray.tune.schedulers import PopulationBasedTraining\n",
    "from ray.tune.tune_config import TuneConfig\n",
    "from ray.tune.tuner import Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "33780ae5-f019-401c-8815-629deb0e888a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset) // session.get_world_size()\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def validate_epoch(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset) // session.get_world_size()\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(\n",
    "        f\"Test Error: \\n \"\n",
    "        f\"Accuracy: {(100 * correct):>0.1f}%, \"\n",
    "        f\"Avg loss: {test_loss:>8f} \\n\"\n",
    "    )\n",
    "    return {\"loss\": test_loss}\n",
    "\n",
    "\n",
    "def update_optimizer_config(optimizer, config):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        for param, val in config.items():\n",
    "            param_group[param] = val\n",
    "\n",
    "\n",
    "def train_func(config):\n",
    "    epochs = config.get(\"epochs\", 3)\n",
    "\n",
    "    model = resnet18()\n",
    "\n",
    "    # Note that `prepare_model` needs to be called before setting optimizer.\n",
    "    if not session.get_checkpoint():  # fresh start\n",
    "        model = train.torch.prepare_model(model)\n",
    "\n",
    "    # Create optimizer.\n",
    "    optimizer_config = {\n",
    "        \"lr\": config.get(\"lr\"),\n",
    "        \"momentum\": config.get(\"momentum\"),\n",
    "    }\n",
    "    optimizer = torch.optim.SGD(model.parameters(), **optimizer_config)\n",
    "\n",
    "    starting_epoch = 0\n",
    "    if session.get_checkpoint():\n",
    "        checkpoint_dict = session.get_checkpoint().to_dict()\n",
    "\n",
    "        # Load in model\n",
    "        model_state = checkpoint_dict[\"model\"]\n",
    "        model.load_state_dict(model_state)\n",
    "        model = train.torch.prepare_model(model)\n",
    "\n",
    "        # Load in optimizer\n",
    "        optimizer_state = checkpoint_dict[\"optimizer_state_dict\"]\n",
    "        optimizer.load_state_dict(optimizer_state)\n",
    "\n",
    "        # Optimizer configs (`lr`, `momentum`) are being mutated by PBT and passed in\n",
    "        # through config, so we need to update the optimizer loaded from the checkpoint\n",
    "        update_optimizer_config(optimizer, optimizer_config)\n",
    "\n",
    "        # The current epoch increments the loaded epoch by 1\n",
    "        checkpoint_epoch = checkpoint_dict[\"epoch\"]\n",
    "        starting_epoch = checkpoint_epoch + 1\n",
    "\n",
    "    # Load in training and validation data.\n",
    "    transform_train = transforms.Compose(\n",
    "        [\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ]\n",
    "    )  # meanstd transformation\n",
    "\n",
    "    transform_test = transforms.Compose(\n",
    "        [\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    data_dir = config.get(\"data_dir\", os.path.expanduser(\"~/data\"))\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    with FileLock(os.path.join(data_dir, \".ray.lock\")):\n",
    "        train_dataset = CIFAR10(\n",
    "            root=data_dir, train=True, download=True, transform=transform_train\n",
    "        )\n",
    "        validation_dataset = CIFAR10(\n",
    "            root=data_dir, train=False, download=False, transform=transform_test\n",
    "        )\n",
    "\n",
    "    if config.get(\"test_mode\"):\n",
    "        train_dataset = Subset(train_dataset, list(range(64)))\n",
    "        validation_dataset = Subset(validation_dataset, list(range(64)))\n",
    "\n",
    "    worker_batch_size = config[\"batch_size\"] // session.get_world_size()\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=worker_batch_size)\n",
    "    validation_loader = DataLoader(validation_dataset, batch_size=worker_batch_size)\n",
    "\n",
    "    train_loader = train.torch.prepare_data_loader(train_loader)\n",
    "    validation_loader = train.torch.prepare_data_loader(validation_loader)\n",
    "\n",
    "    # Create loss.\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(starting_epoch, epochs):\n",
    "        train_epoch(train_loader, model, criterion, optimizer)\n",
    "        result = validate_epoch(validation_loader, model, criterion)\n",
    "        checkpoint = Checkpoint.from_dict(\n",
    "            {\n",
    "                \"epoch\": epoch,\n",
    "                \"model\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "            }\n",
    "        )\n",
    "\n",
    "        session.report(result, checkpoint=checkpoint)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a3166e5-33cf-4d80-8a76-520ad72015c9",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1776de4f-6b8b-4d88-b63b-de1dd1d07e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRATCH = os.getenv('SCRATCH')\n",
    "\n",
    "node_resources = ray.cluster_resources()\n",
    "num_workers = int(node_resources['GPU'])\n",
    "use_gpu = True\n",
    "\n",
    "data_dir = os.path.join(SCRATCH, 'CIFAR10')\n",
    "num_epochs = 5\n",
    "smoke_test = False\n",
    "synch = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cc38a5e-6416-4d30-aa64-1522d19434e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TorchTrainer(\n",
    "        train_func,\n",
    "        scaling_config=ScalingConfig(\n",
    "            num_workers=num_workers, use_gpu=use_gpu\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5fe99e52-491f-4bad-8f9b-89f07dddf497",
   "metadata": {},
   "outputs": [],
   "source": [
    "pbt_scheduler = PopulationBasedTraining(\n",
    "        time_attr=\"training_iteration\",\n",
    "        perturbation_interval=1,\n",
    "        hyperparam_mutations={\n",
    "            \"train_loop_config\": {\n",
    "                # distribution for resampling\n",
    "                \"lr\": tune.loguniform(0.001, 0.1),\n",
    "                # allow perturbations within this set of categorical values\n",
    "                \"momentum\": [0.8, 0.9, 0.99],\n",
    "            }\n",
    "        },\n",
    "        synch=synch,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f0e4054-3899-4546-bbac-eb8f35b6cb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner = Tuner(\n",
    "        trainer,\n",
    "        param_space={\n",
    "            \"train_loop_config\": {\n",
    "                \"lr\": tune.grid_search([0.001, 0.01, 0.05, 0.1]),\n",
    "                \"momentum\": 0.8,\n",
    "                \"batch_size\": 128 * num_workers,\n",
    "                \"test_mode\": smoke_test,  # whether to to subset the data\n",
    "                \"data_dir\": data_dir,\n",
    "                \"epochs\": num_epochs,\n",
    "            }\n",
    "        },\n",
    "        tune_config=TuneConfig(\n",
    "            num_samples=1, metric=\"loss\", mode=\"min\", scheduler=pbt_scheduler\n",
    "        ),\n",
    "        run_config=RunConfig(\n",
    "            stop={\"training_iteration\": 3 if smoke_test else num_epochs},\n",
    "            failure_config=FailureConfig(max_failures=3),  # used for fault tolerance\n",
    "        ),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6db72506-8d82-44ab-9777-ca6e414e1c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2023-03-03 19:29:11</td></tr>\n",
       "<tr><td>Running for: </td><td>00:08:22.13        </td></tr>\n",
       "<tr><td>Memory:      </td><td>63.6/251.3 GiB     </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      PopulationBasedTraining: 6 checkpoints, 3 perturbs<br>Resources requested: 0/256 CPUs, 0/8 GPUs, 0.0/309.42 GiB heap, 0.0/136.6 GiB objects (0.0/2.0 accelerator_type:A100)\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status    </th><th>loc                 </th><th style=\"text-align: right;\">  train_loop_config/lr</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">  _timestamp</th><th style=\"text-align: right;\">  _time_this_iter_s</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_8f5ae_00000</td><td>TERMINATED</td><td>pid=78729           </td><td style=\"text-align: right;\">                 0.06 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         99.1326</td><td style=\"text-align: right;\">0.985433</td><td style=\"text-align: right;\">  1677900479</td><td style=\"text-align: right;\">            15.4285</td></tr>\n",
       "<tr><td>TorchTrainer_8f5ae_00001</td><td>TERMINATED</td><td>10.249.19.154:108482</td><td style=\"text-align: right;\">                 0.072</td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         99.1398</td><td style=\"text-align: right;\">1.01094 </td><td style=\"text-align: right;\">  1677900502</td><td style=\"text-align: right;\">            15.3436</td></tr>\n",
       "<tr><td>TorchTrainer_8f5ae_00002</td><td>TERMINATED</td><td>pid=80619           </td><td style=\"text-align: right;\">                 0.05 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         99.0159</td><td style=\"text-align: right;\">1.00415 </td><td style=\"text-align: right;\">  1677900526</td><td style=\"text-align: right;\">            15.4466</td></tr>\n",
       "<tr><td>TorchTrainer_8f5ae_00003</td><td>TERMINATED</td><td>pid=81595           </td><td style=\"text-align: right;\">                 0.04 </td><td style=\"text-align: right;\">     5</td><td style=\"text-align: right;\">         99.4392</td><td style=\"text-align: right;\">1.04827 </td><td style=\"text-align: right;\">  1677900550</td><td style=\"text-align: right;\">            15.3058</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m /global/homes/a/asnaylor/.local/perlmutter/pytorch1.13.1/lib/python3.9/site-packages/ray/tune/tune.py:562: UserWarning: Consider boosting PBT performance by enabling `reuse_actors` as well as implementing `reset_config` for Trainable.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warnings.warn(\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:20:48,989\tWARNING trial_runner.py:369 -- The maximum number of pending trials has been automatically set to the number of available cluster CPUs, which is high (281 CPUs/pending trials). If you're running an experiment with a large number of trials, this could lead to scheduling overhead. In this case, consider setting the `TUNE_MAX_PENDING_TRIALS_PG` environment variable to the desired maximum number of concurrent trials.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:20:48,993\tWARNING trial_runner.py:1677 -- You are trying to access _search_alg interface of TrialRunner in TrialScheduler, which is being restricted. If you believe it is reasonable for your scheduler to access this TrialRunner API, please reach out to Ray team on GitHub. A more strict API access pattern would be enforced starting 1.12s.0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61784)\u001b[0m 2023-03-03 19:20:58,111\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61784)\u001b[0m 2023-03-03 19:21:00,799\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98660, ip=128.55.69.178)\u001b[0m 2023-03-03 19:21:00,855\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61784)\u001b[0m 2023-03-03 19:21:02,923\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98660, ip=128.55.69.178)\u001b[0m 2023-03-03 19:21:02,934\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61784)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61787)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61786)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61785)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98657, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98658, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98660, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98659, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98659, ip=128.55.69.178)\u001b[0m loss: 7.233888  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98658, ip=128.55.69.178)\u001b[0m loss: 7.088008  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98657, ip=128.55.69.178)\u001b[0m loss: 7.143627  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98660, ip=128.55.69.178)\u001b[0m loss: 7.204629  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61784)\u001b[0m loss: 7.228695  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61787)\u001b[0m loss: 7.124676  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61785)\u001b[0m loss: 7.169736  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61786)\u001b[0m loss: 7.101164  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98659, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98659, ip=128.55.69.178)\u001b[0m  Accuracy: 24.0%, Avg loss: 2.533078 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98659, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98658, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98658, ip=128.55.69.178)\u001b[0m  Accuracy: 24.4%, Avg loss: 2.544651 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98658, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98657, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98657, ip=128.55.69.178)\u001b[0m  Accuracy: 23.8%, Avg loss: 2.532307 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98657, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98660, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98660, ip=128.55.69.178)\u001b[0m  Accuracy: 23.5%, Avg loss: 2.527342 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98660, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61784)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61784)\u001b[0m  Accuracy: 24.0%, Avg loss: 2.534120 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61784)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61787)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61787)\u001b[0m  Accuracy: 23.4%, Avg loss: 2.528959 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61787)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61785)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61785)\u001b[0m  Accuracy: 23.6%, Avg loss: 2.528251 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61785)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61786)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61786)\u001b[0m  Accuracy: 23.9%, Avg loss: 2.553672 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61786)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 17.56462812423706\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900077\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-21-17\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: 3bc6f6f6e6f14ed7acb0989850ce3a74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 2.534119749069214\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 61613\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 25.8347487449646\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 25.8347487449646\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 25.8347487449646\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900077\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.1579444408416748\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98659, ip=128.55.69.178)\u001b[0m loss: 2.379839  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98658, ip=128.55.69.178)\u001b[0m loss: 2.414728  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98657, ip=128.55.69.178)\u001b[0m loss: 2.340582  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=98660, ip=128.55.69.178)\u001b[0m loss: 2.366014  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61784)\u001b[0m loss: 2.339765  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61787)\u001b[0m loss: 2.400145  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61785)\u001b[0m loss: 2.331088  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=61786)\u001b[0m loss: 2.351198  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62849)\u001b[0m 2023-03-03 19:21:23,577\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62849)\u001b[0m 2023-03-03 19:21:25,488\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:2\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99128, ip=128.55.69.178)\u001b[0m 2023-03-03 19:21:25,529\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99128, ip=128.55.69.178)\u001b[0m 2023-03-03 19:21:27,023\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62849)\u001b[0m 2023-03-03 19:21:27,085\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62850)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62849)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62852)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99131, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99130, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99129, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99128, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62851)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62852)\u001b[0m loss: 7.217724  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62851)\u001b[0m loss: 7.198362  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62850)\u001b[0m loss: 7.171299  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62849)\u001b[0m loss: 7.220249  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99131, ip=128.55.69.178)\u001b[0m loss: 7.113987  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99130, ip=128.55.69.178)\u001b[0m loss: 6.981210  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99129, ip=128.55.69.178)\u001b[0m loss: 7.205013  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99128, ip=128.55.69.178)\u001b[0m loss: 7.076631  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62852)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62852)\u001b[0m  Accuracy: 38.7%, Avg loss: 1.628648 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62852)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62851)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62851)\u001b[0m  Accuracy: 40.2%, Avg loss: 1.634250 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62851)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62850)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62850)\u001b[0m  Accuracy: 39.8%, Avg loss: 1.626885 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62850)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62849)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62849)\u001b[0m  Accuracy: 40.6%, Avg loss: 1.639367 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62849)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99131, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99131, ip=128.55.69.178)\u001b[0m  Accuracy: 41.4%, Avg loss: 1.608499 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99131, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99130, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99130, ip=128.55.69.178)\u001b[0m  Accuracy: 40.2%, Avg loss: 1.650498 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99130, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99129, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99129, ip=128.55.69.178)\u001b[0m  Accuracy: 37.2%, Avg loss: 1.681480 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99129, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99128, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99128, ip=128.55.69.178)\u001b[0m  Accuracy: 42.5%, Avg loss: 1.649372 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99128, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99131, ip=128.55.69.178)\u001b[0m loss: 1.839801  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99130, ip=128.55.69.178)\u001b[0m loss: 1.674299  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99129, ip=128.55.69.178)\u001b[0m loss: 1.676811  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99128, ip=128.55.69.178)\u001b[0m loss: 1.693282  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 14.022783517837524\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900099\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-21-39\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: 6a7c912915ea446c99c8693563996683\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.639366865158081\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 62715\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 18.498899221420288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 18.498899221420288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 18.498899221420288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900099\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.15924787521362305\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62852)\u001b[0m loss: 1.665893  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62851)\u001b[0m loss: 1.705136  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62850)\u001b[0m loss: 1.711496  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=62849)\u001b[0m loss: 1.661788  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63837)\u001b[0m 2023-03-03 19:21:45,564\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63837)\u001b[0m 2023-03-03 19:21:47,329\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99625, ip=128.55.69.178)\u001b[0m 2023-03-03 19:21:47,395\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99625, ip=128.55.69.178)\u001b[0m 2023-03-03 19:21:48,908\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63837)\u001b[0m 2023-03-03 19:21:49,001\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99628, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99626, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63839)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63838)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63837)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63840)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99625, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99627, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99627, ip=128.55.69.178)\u001b[0m loss: 7.026409  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99628, ip=128.55.69.178)\u001b[0m loss: 7.051173  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99626, ip=128.55.69.178)\u001b[0m loss: 7.136610  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99625, ip=128.55.69.178)\u001b[0m loss: 7.123416  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63839)\u001b[0m loss: 7.171196  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63840)\u001b[0m loss: 6.940555  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63837)\u001b[0m loss: 7.186929  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63838)\u001b[0m loss: 7.109013  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99627, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99627, ip=128.55.69.178)\u001b[0m  Accuracy: 44.6%, Avg loss: 1.472066 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99627, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99628, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99628, ip=128.55.69.178)\u001b[0m  Accuracy: 47.4%, Avg loss: 1.438184 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99628, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99626, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99626, ip=128.55.69.178)\u001b[0m  Accuracy: 45.5%, Avg loss: 1.470928 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99626, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99625, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99625, ip=128.55.69.178)\u001b[0m  Accuracy: 47.4%, Avg loss: 1.461224 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99625, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63839)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63839)\u001b[0m  Accuracy: 46.4%, Avg loss: 1.476648 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63839)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63840)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63840)\u001b[0m  Accuracy: 47.4%, Avg loss: 1.436250 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63840)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63837)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63837)\u001b[0m  Accuracy: 48.0%, Avg loss: 1.416393 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63837)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63838)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63838)\u001b[0m  Accuracy: 45.8%, Avg loss: 1.467436 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63838)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 14.221242189407349\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900121\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-22-01\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.4163928031921387\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 63703\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 18.63059902191162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 18.63059902191162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 18.63059902191162\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900121\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.22081303596496582\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63839)\u001b[0m loss: 1.440026  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63840)\u001b[0m loss: 1.640148  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63837)\u001b[0m loss: 1.410383  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=63838)\u001b[0m loss: 1.459079  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99627, ip=128.55.69.178)\u001b[0m loss: 1.517214  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99628, ip=128.55.69.178)\u001b[0m loss: 1.482663  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99626, ip=128.55.69.178)\u001b[0m loss: 1.564084  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=99625, ip=128.55.69.178)\u001b[0m loss: 1.464827  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m 2023-03-03 19:22:09,156\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m 2023-03-03 19:22:11,104\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:2\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m 2023-03-03 19:22:11,074\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:2\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m 2023-03-03 19:22:12,625\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m 2023-03-03 19:22:12,775\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100201, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100200, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64725)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64727)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64726)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100199, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64725)\u001b[0m loss: 7.380192  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m loss: 7.478827  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64727)\u001b[0m loss: 7.547189  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64726)\u001b[0m loss: 7.476220  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100199, ip=128.55.69.178)\u001b[0m loss: 7.466144  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m loss: 7.481565  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100200, ip=128.55.69.178)\u001b[0m loss: 7.563566  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100201, ip=128.55.69.178)\u001b[0m loss: 7.512176  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64725)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64725)\u001b[0m  Accuracy: 35.8%, Avg loss: 1.741587 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64725)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m  Accuracy: 37.7%, Avg loss: 1.698851 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64727)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64727)\u001b[0m  Accuracy: 40.6%, Avg loss: 1.647030 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64727)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64726)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64726)\u001b[0m  Accuracy: 35.4%, Avg loss: 1.714851 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64726)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100199, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100199, ip=128.55.69.178)\u001b[0m  Accuracy: 39.2%, Avg loss: 1.654574 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100199, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m  Accuracy: 39.7%, Avg loss: 1.650243 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100200, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100200, ip=128.55.69.178)\u001b[0m  Accuracy: 38.4%, Avg loss: 1.690864 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100200, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100201, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100201, ip=128.55.69.178)\u001b[0m  Accuracy: 37.9%, Avg loss: 1.644727 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100201, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 14.163927555084229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-22-25\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d5bbb6808c4c4baba6fd4d28281a9a8e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.6502429008483888\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: 10.249.19.154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 100101\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 18.72793674468994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 18.72793674468994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 18.72793674468994\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900145\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.17264032363891602\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64725)\u001b[0m loss: 1.730615  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m loss: 1.677741  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64727)\u001b[0m loss: 1.757167  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64726)\u001b[0m loss: 1.679482  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100199, ip=128.55.69.178)\u001b[0m loss: 1.642385  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m loss: 1.599105  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100200, ip=128.55.69.178)\u001b[0m loss: 1.681688  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100201, ip=128.55.69.178)\u001b[0m loss: 1.662198  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64725)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64725)\u001b[0m  Accuracy: 47.7%, Avg loss: 1.546276 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64725)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m  Accuracy: 46.6%, Avg loss: 1.478272 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64724)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64727)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64727)\u001b[0m  Accuracy: 48.2%, Avg loss: 1.523408 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64727)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64726)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64726)\u001b[0m  Accuracy: 45.1%, Avg loss: 1.551777 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=64726)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100199, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100199, ip=128.55.69.178)\u001b[0m  Accuracy: 47.4%, Avg loss: 1.506711 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100199, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m  Accuracy: 49.1%, Avg loss: 1.552247 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100198, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100200, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100200, ip=128.55.69.178)\u001b[0m  Accuracy: 47.9%, Avg loss: 1.540136 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100200, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100201, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100201, ip=128.55.69.178)\u001b[0m  Accuracy: 49.1%, Avg loss: 1.436211 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100201, ip=128.55.69.178)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:22:27,916\tWARNING util.py:244 -- The `process_trial_save` operation took 2.561 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:22:27,916\tWARNING trial_runner.py:1033 -- Consider turning off forced head-worker trial checkpoint syncs by setting sync_on_checkpoint=False. Note that this may result in faulty trial restoration if a failure occurs while the checkpoint is being synced from the worker to the head node.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=100861, ip=128.55.69.178)\u001b[0m 2023-03-03 19:22:31,259\tINFO trainable.py:791 -- Restored on 10.249.19.154 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00000_0_lr=0.0010_2023-03-03_19-20-49/checkpoint_tmpb1d240\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=100861, ip=128.55.69.178)\u001b[0m 2023-03-03 19:22:31,259\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 25.8347487449646, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100958, ip=128.55.69.178)\u001b[0m 2023-03-03 19:22:33,803\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100958, ip=128.55.69.178)\u001b[0m 2023-03-03 19:22:37,293\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65641)\u001b[0m 2023-03-03 19:22:37,252\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100958, ip=128.55.69.178)\u001b[0m 2023-03-03 19:22:38,749\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65641)\u001b[0m 2023-03-03 19:22:38,841\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65641)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65646)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65644)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100958, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100959, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100960, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100961, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65642)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100960, ip=128.55.69.178)\u001b[0m loss: 2.387163  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100961, ip=128.55.69.178)\u001b[0m loss: 2.425263  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100959, ip=128.55.69.178)\u001b[0m loss: 2.359572  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100958, ip=128.55.69.178)\u001b[0m loss: 2.385702  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65646)\u001b[0m loss: 2.391721  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65644)\u001b[0m loss: 2.381195  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65642)\u001b[0m loss: 2.402007  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65641)\u001b[0m loss: 2.317456  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65646)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65646)\u001b[0m  Accuracy: 27.8%, Avg loss: 2.003012 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65646)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65644)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65644)\u001b[0m  Accuracy: 29.7%, Avg loss: 2.000288 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65644)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65642)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65642)\u001b[0m  Accuracy: 32.1%, Avg loss: 1.983372 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65642)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65641)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65641)\u001b[0m  Accuracy: 29.3%, Avg loss: 2.008322 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=65641)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100960, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100960, ip=128.55.69.178)\u001b[0m  Accuracy: 28.2%, Avg loss: 2.026919 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100960, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100961, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100961, ip=128.55.69.178)\u001b[0m  Accuracy: 30.1%, Avg loss: 1.973711 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100961, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100959, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100959, ip=128.55.69.178)\u001b[0m  Accuracy: 28.6%, Avg loss: 1.982712 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100959, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100958, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100958, ip=128.55.69.178)\u001b[0m  Accuracy: 28.2%, Avg loss: 1.994845 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=100958, ip=128.55.69.178)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:22:51,121\tINFO pbt.py:804 -- \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m [PopulationBasedTraining] [Exploit] Cloning trial 8f5ae_00002 (score = -1.416393) into trial 8f5ae_00000 (score = -1.994845)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:22:51,122\tINFO pbt.py:831 -- \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m [PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8f5ae_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m train_loop_config : \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m     lr : 0.05 --- (* 1.2) --> 0.06\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m     momentum : 0.8 --- (resample) --> 0.9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.14406132698059\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900170\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-22-51\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: 3bc6f6f6e6f14ed7acb0989850ce3a74\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.9948448538780212\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: 10.249.19.154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 100861\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 19.860088348388672\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 19.860088348388672\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 45.69483709335327\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900171\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.36803126335144043\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=66486)\u001b[0m 2023-03-03 19:22:54,203\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00000_0_lr=0.0010_2023-03-03_19-20-49/checkpoint_tmp2525d5\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=66486)\u001b[0m 2023-03-03 19:22:54,203\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 18.63059902191162, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66620)\u001b[0m 2023-03-03 19:22:56,676\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66620)\u001b[0m 2023-03-03 19:23:00,000\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101469, ip=128.55.69.178)\u001b[0m 2023-03-03 19:22:59,993\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101469, ip=128.55.69.178)\u001b[0m 2023-03-03 19:23:01,560\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66620)\u001b[0m 2023-03-03 19:23:01,718\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66620)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66622)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66625)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66624)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101472, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101471, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101469, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101470, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66625)\u001b[0m loss: 1.564933  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66622)\u001b[0m loss: 1.461504  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66624)\u001b[0m loss: 1.509070  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66620)\u001b[0m loss: 1.462853  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101472, ip=128.55.69.178)\u001b[0m loss: 1.586576  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101471, ip=128.55.69.178)\u001b[0m loss: 1.488603  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101470, ip=128.55.69.178)\u001b[0m loss: 1.552278  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101469, ip=128.55.69.178)\u001b[0m loss: 1.442976  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66625)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66625)\u001b[0m  Accuracy: 50.1%, Avg loss: 1.474838 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66625)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66622)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66622)\u001b[0m  Accuracy: 46.7%, Avg loss: 1.563970 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66622)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66624)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66624)\u001b[0m  Accuracy: 49.3%, Avg loss: 1.510528 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66624)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66620)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66620)\u001b[0m  Accuracy: 50.7%, Avg loss: 1.488460 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66620)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101472, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101472, ip=128.55.69.178)\u001b[0m  Accuracy: 50.2%, Avg loss: 1.466457 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101472, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101471, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101471, ip=128.55.69.178)\u001b[0m  Accuracy: 47.5%, Avg loss: 1.530593 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101471, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101470, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101470, ip=128.55.69.178)\u001b[0m  Accuracy: 47.3%, Avg loss: 1.551877 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101470, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101469, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101469, ip=128.55.69.178)\u001b[0m  Accuracy: 49.2%, Avg loss: 1.533615 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101469, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66625)\u001b[0m loss: 1.340386  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66622)\u001b[0m loss: 1.235209  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66624)\u001b[0m loss: 1.334768  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=66620)\u001b[0m loss: 1.345555  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101472, ip=128.55.69.178)\u001b[0m loss: 1.366315  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101471, ip=128.55.69.178)\u001b[0m loss: 1.327430  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101470, ip=128.55.69.178)\u001b[0m loss: 1.333975  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101469, ip=128.55.69.178)\u001b[0m loss: 1.419857  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=67450)\u001b[0m 2023-03-03 19:23:17,222\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00001_1_lr=0.0100_2023-03-03_19-21-18/checkpoint_tmp1b7202\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=67450)\u001b[0m 2023-03-03 19:23:17,222\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 18.498899221420288, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67592)\u001b[0m 2023-03-03 19:23:19,877\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67592)\u001b[0m 2023-03-03 19:23:23,308\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101998, ip=128.55.69.178)\u001b[0m 2023-03-03 19:23:23,364\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101998, ip=128.55.69.178)\u001b[0m 2023-03-03 19:23:24,929\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67592)\u001b[0m 2023-03-03 19:23:25,013\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67592)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102000, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101999, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67594)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102001, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101998, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67595)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67593)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67595)\u001b[0m loss: 1.654110  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67594)\u001b[0m loss: 1.756918  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67592)\u001b[0m loss: 1.708636  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67593)\u001b[0m loss: 1.584543  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101998, ip=128.55.69.178)\u001b[0m loss: 1.630245  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101999, ip=128.55.69.178)\u001b[0m loss: 1.718705  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102001, ip=128.55.69.178)\u001b[0m loss: 1.632529  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102000, ip=128.55.69.178)\u001b[0m loss: 1.645478  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67595)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67595)\u001b[0m  Accuracy: 46.3%, Avg loss: 1.501677 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67595)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67594)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67594)\u001b[0m  Accuracy: 44.8%, Avg loss: 1.449568 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67594)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67592)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67592)\u001b[0m  Accuracy: 48.5%, Avg loss: 1.455788 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67592)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67593)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67593)\u001b[0m  Accuracy: 46.1%, Avg loss: 1.472423 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67593)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101998, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101998, ip=128.55.69.178)\u001b[0m  Accuracy: 45.1%, Avg loss: 1.506693 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101998, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101999, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101999, ip=128.55.69.178)\u001b[0m  Accuracy: 45.9%, Avg loss: 1.492297 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101999, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102001, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102001, ip=128.55.69.178)\u001b[0m  Accuracy: 46.9%, Avg loss: 1.439746 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102001, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102000, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102000, ip=128.55.69.178)\u001b[0m  Accuracy: 42.9%, Avg loss: 1.514707 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102000, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.334102869033813\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-23-37\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: 6a7c912915ea446c99c8693563996683\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.4557877779006958\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 67450\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.199848175048828\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.199848175048828\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 38.698747396469116\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.3155694007873535\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101998, ip=128.55.69.178)\u001b[0m loss: 1.397614  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=101999, ip=128.55.69.178)\u001b[0m loss: 1.575830  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102001, ip=128.55.69.178)\u001b[0m loss: 1.606783  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102000, ip=128.55.69.178)\u001b[0m loss: 1.590089  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67595)\u001b[0m loss: 1.403674  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67594)\u001b[0m loss: 1.550163  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67592)\u001b[0m loss: 1.484038  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=67593)\u001b[0m loss: 1.502731  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=68415)\u001b[0m 2023-03-03 19:23:40,219\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00002_2_lr=0.0500_2023-03-03_19-21-40/checkpoint_tmp6c8151\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=68415)\u001b[0m 2023-03-03 19:23:40,219\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 18.63059902191162, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68568)\u001b[0m 2023-03-03 19:23:42,740\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68568)\u001b[0m 2023-03-03 19:23:46,097\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102467, ip=128.55.69.178)\u001b[0m 2023-03-03 19:23:46,065\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102467, ip=128.55.69.178)\u001b[0m 2023-03-03 19:23:47,571\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68568)\u001b[0m 2023-03-03 19:23:47,679\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102468, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68571)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102469, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68569)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102467, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68570)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68568)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102470, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102468, ip=128.55.69.178)\u001b[0m loss: 1.514647  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102470, ip=128.55.69.178)\u001b[0m loss: 1.545555  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102469, ip=128.55.69.178)\u001b[0m loss: 1.541115  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102467, ip=128.55.69.178)\u001b[0m loss: 1.447667  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68571)\u001b[0m loss: 1.532532  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68569)\u001b[0m loss: 1.402612  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68570)\u001b[0m loss: 1.404109  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68568)\u001b[0m loss: 1.442758  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102468, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102468, ip=128.55.69.178)\u001b[0m  Accuracy: 50.2%, Avg loss: 1.346222 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102468, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102469, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102469, ip=128.55.69.178)\u001b[0m  Accuracy: 50.9%, Avg loss: 1.329370 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102469, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102467, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102467, ip=128.55.69.178)\u001b[0m  Accuracy: 52.1%, Avg loss: 1.325356 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102467, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102470, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102470, ip=128.55.69.178)\u001b[0m  Accuracy: 52.8%, Avg loss: 1.259020 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102470, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68571)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68571)\u001b[0m  Accuracy: 54.2%, Avg loss: 1.238483 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68571)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68569)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68569)\u001b[0m  Accuracy: 51.0%, Avg loss: 1.341254 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68569)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68570)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68570)\u001b[0m  Accuracy: 51.9%, Avg loss: 1.323257 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68570)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68568)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68568)\u001b[0m  Accuracy: 53.6%, Avg loss: 1.303070 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68568)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102468, ip=128.55.69.178)\u001b[0m loss: 1.306834  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102470, ip=128.55.69.178)\u001b[0m loss: 1.438356  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102469, ip=128.55.69.178)\u001b[0m loss: 1.338474  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=102467, ip=128.55.69.178)\u001b[0m loss: 1.296594  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.198473930358887\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900239\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-24-00\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.30307035446167\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 68415\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 19.83760666847229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 19.83760666847229\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 38.46820569038391\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900240\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.29561758041381836\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68571)\u001b[0m loss: 1.477857  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68569)\u001b[0m loss: 1.272848  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68570)\u001b[0m loss: 1.322523  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=68568)\u001b[0m loss: 1.262674  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=69448)\u001b[0m 2023-03-03 19:24:04,176\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00003_3_lr=0.1000_2023-03-03_19-22-02/checkpoint_tmp6aeefd\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=69448)\u001b[0m 2023-03-03 19:24:04,176\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 1, '_timesteps_total': None, '_time_total': 18.72793674468994, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69597)\u001b[0m 2023-03-03 19:24:06,888\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103011, ip=128.55.69.178)\u001b[0m 2023-03-03 19:24:10,224\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69597)\u001b[0m 2023-03-03 19:24:10,231\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103011, ip=128.55.69.178)\u001b[0m 2023-03-03 19:24:11,788\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69597)\u001b[0m 2023-03-03 19:24:11,833\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103012, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103013, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103014, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103011, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69599)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69600)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69597)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69598)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103013, ip=128.55.69.178)\u001b[0m loss: 1.696166  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103014, ip=128.55.69.178)\u001b[0m loss: 1.796499  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103012, ip=128.55.69.178)\u001b[0m loss: 1.820550  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103011, ip=128.55.69.178)\u001b[0m loss: 1.683577  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69600)\u001b[0m loss: 1.721351  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69599)\u001b[0m loss: 1.661578  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69598)\u001b[0m loss: 1.672083  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69597)\u001b[0m loss: 1.567204  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103013, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103013, ip=128.55.69.178)\u001b[0m  Accuracy: 47.1%, Avg loss: 1.553305 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103013, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103014, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103014, ip=128.55.69.178)\u001b[0m  Accuracy: 48.2%, Avg loss: 1.506868 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103014, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103012, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103012, ip=128.55.69.178)\u001b[0m  Accuracy: 47.4%, Avg loss: 1.573608 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103012, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103011, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103011, ip=128.55.69.178)\u001b[0m  Accuracy: 48.3%, Avg loss: 1.530615 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103011, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69600)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69600)\u001b[0m  Accuracy: 47.4%, Avg loss: 1.501110 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69600)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69599)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69599)\u001b[0m  Accuracy: 50.7%, Avg loss: 1.467293 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69599)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69598)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69598)\u001b[0m  Accuracy: 48.2%, Avg loss: 1.494673 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69598)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69597)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69597)\u001b[0m  Accuracy: 49.6%, Avg loss: 1.515052 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=69597)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:24:24,313\tINFO pbt.py:804 -- \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m [PopulationBasedTraining] [Exploit] Cloning trial 8f5ae_00002 (score = -1.303070) into trial 8f5ae_00003 (score = -1.515052)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:24:24,314\tINFO pbt.py:831 -- \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m [PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8f5ae_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m train_loop_config : \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m     lr : 0.05 --- (* 0.8) --> 0.04000000000000001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m     momentum : 0.8 --- (shift left (noop)) --> 0.8\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.373709678649902\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900264\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-24-24\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d5bbb6808c4c4baba6fd4d28281a9a8e\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.515051782131195\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 69448\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.13590693473816\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.13590693473816\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 38.8638436794281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900264\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 2\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.5316381454467773\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=103480, ip=128.55.69.178)\u001b[0m 2023-03-03 19:24:27,891\tINFO trainable.py:791 -- Restored on 10.249.19.154 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00000_0_lr=0.0010_2023-03-03_19-20-49/checkpoint_tmp683cd2\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=103480, ip=128.55.69.178)\u001b[0m 2023-03-03 19:24:27,891\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 2, '_timesteps_total': None, '_time_total': 38.65552496910095, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103577, ip=128.55.69.178)\u001b[0m 2023-03-03 19:24:30,537\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103577, ip=128.55.69.178)\u001b[0m 2023-03-03 19:24:33,983\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70572)\u001b[0m 2023-03-03 19:24:33,947\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70572)\u001b[0m 2023-03-03 19:24:35,554\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103577, ip=128.55.69.178)\u001b[0m 2023-03-03 19:24:35,535\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70575)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70573)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70574)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70572)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103577, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103578, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103579, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103580, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70575)\u001b[0m loss: 1.464871  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70573)\u001b[0m loss: 1.346256  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70574)\u001b[0m loss: 1.403846  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70572)\u001b[0m loss: 1.382998  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103579, ip=128.55.69.178)\u001b[0m loss: 1.271959  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103580, ip=128.55.69.178)\u001b[0m loss: 1.451021  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103578, ip=128.55.69.178)\u001b[0m loss: 1.308346  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103577, ip=128.55.69.178)\u001b[0m loss: 1.391047  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103579, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103579, ip=128.55.69.178)\u001b[0m  Accuracy: 57.3%, Avg loss: 1.311109 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103579, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103578, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103578, ip=128.55.69.178)\u001b[0m  Accuracy: 55.3%, Avg loss: 1.305108 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103578, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103577, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103577, ip=128.55.69.178)\u001b[0m  Accuracy: 59.0%, Avg loss: 1.203247 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103577, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70575)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70575)\u001b[0m  Accuracy: 57.8%, Avg loss: 1.217961 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70575)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70573)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70573)\u001b[0m  Accuracy: 56.7%, Avg loss: 1.278121 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70573)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70574)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70574)\u001b[0m  Accuracy: 57.1%, Avg loss: 1.266704 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70574)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70572)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70572)\u001b[0m  Accuracy: 56.8%, Avg loss: 1.279375 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70572)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103580, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103580, ip=128.55.69.178)\u001b[0m  Accuracy: 58.9%, Avg loss: 1.231102 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103580, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.359623193740845\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900287\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-24-48\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.2032465815544129\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: 10.249.19.154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 103480\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.137666702270508\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.137666702270508\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 58.79319167137146\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900288\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.34046220779418945\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70575)\u001b[0m loss: 1.334371  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70573)\u001b[0m loss: 1.175546  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70574)\u001b[0m loss: 1.221072  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=70572)\u001b[0m loss: 1.320715  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103579, ip=128.55.69.178)\u001b[0m loss: 1.144001  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103580, ip=128.55.69.178)\u001b[0m loss: 1.252148  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103578, ip=128.55.69.178)\u001b[0m loss: 1.142699  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=103577, ip=128.55.69.178)\u001b[0m loss: 1.175709  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:24:49,146\tWARNING util.py:244 -- The `process_trial_save` operation took 1.018 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=71464)\u001b[0m 2023-03-03 19:24:52,221\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00001_1_lr=0.0100_2023-03-03_19-21-18/checkpoint_tmpc678c2\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=71464)\u001b[0m 2023-03-03 19:24:52,221\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 2, '_timesteps_total': None, '_time_total': 38.698747396469116, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71627)\u001b[0m 2023-03-03 19:24:54,754\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104206, ip=128.55.69.178)\u001b[0m 2023-03-03 19:24:58,057\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71627)\u001b[0m 2023-03-03 19:24:58,011\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71627)\u001b[0m 2023-03-03 19:24:59,548\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104206, ip=128.55.69.178)\u001b[0m 2023-03-03 19:24:59,603\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104207, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71631)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71630)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71629)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71627)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104206, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104209, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104208, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104208, ip=128.55.69.178)\u001b[0m loss: 1.521926  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104207, ip=128.55.69.178)\u001b[0m loss: 1.589796  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104206, ip=128.55.69.178)\u001b[0m loss: 1.441181  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104209, ip=128.55.69.178)\u001b[0m loss: 1.570727  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71627)\u001b[0m loss: 1.491485  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71631)\u001b[0m loss: 1.442548  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71629)\u001b[0m loss: 1.419073  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71630)\u001b[0m loss: 1.566732  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104206, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104206, ip=128.55.69.178)\u001b[0m  Accuracy: 49.0%, Avg loss: 1.403039 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104206, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71627)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71627)\u001b[0m  Accuracy: 51.8%, Avg loss: 1.361219 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71627)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71631)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71631)\u001b[0m  Accuracy: 48.4%, Avg loss: 1.416333 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71631)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71629)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71629)\u001b[0m  Accuracy: 49.2%, Avg loss: 1.381697 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71629)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71630)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71630)\u001b[0m  Accuracy: 47.8%, Avg loss: 1.368785 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71630)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104208, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104208, ip=128.55.69.178)\u001b[0m  Accuracy: 46.5%, Avg loss: 1.418932 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104208, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104207, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104207, ip=128.55.69.178)\u001b[0m  Accuracy: 50.0%, Avg loss: 1.396597 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104207, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104209, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104209, ip=128.55.69.178)\u001b[0m  Accuracy: 50.4%, Avg loss: 1.364024 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104209, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.169657230377197\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900311\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-25-11\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: 6a7c912915ea446c99c8693563996683\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.3612193703651427\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 71464\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 19.75464677810669\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 19.75464677810669\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 58.453394174575806\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900311\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.2911226749420166\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104208, ip=128.55.69.178)\u001b[0m loss: 1.359474  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104207, ip=128.55.69.178)\u001b[0m loss: 1.482494  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104206, ip=128.55.69.178)\u001b[0m loss: 1.345951  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104209, ip=128.55.69.178)\u001b[0m loss: 1.486683  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71627)\u001b[0m loss: 1.419074  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71631)\u001b[0m loss: 1.387232  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71629)\u001b[0m loss: 1.425467  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=71630)\u001b[0m loss: 1.538751  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=72529)\u001b[0m 2023-03-03 19:25:15,692\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00002_2_lr=0.0500_2023-03-03_19-21-40/checkpoint_tmp517b40\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=72529)\u001b[0m 2023-03-03 19:25:15,692\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 2, '_timesteps_total': None, '_time_total': 38.46820569038391, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72714)\u001b[0m 2023-03-03 19:25:18,440\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104674, ip=128.55.69.178)\u001b[0m 2023-03-03 19:25:21,744\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72714)\u001b[0m 2023-03-03 19:25:21,784\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104674, ip=128.55.69.178)\u001b[0m 2023-03-03 19:25:23,274\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72714)\u001b[0m 2023-03-03 19:25:23,398\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104674, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104675, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72714)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72717)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104677, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104676, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72718)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72716)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104677, ip=128.55.69.178)\u001b[0m loss: 1.434514  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104676, ip=128.55.69.178)\u001b[0m loss: 1.328148  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104675, ip=128.55.69.178)\u001b[0m loss: 1.252781  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104674, ip=128.55.69.178)\u001b[0m loss: 1.340302  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72718)\u001b[0m loss: 1.303026  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72717)\u001b[0m loss: 1.417787  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72716)\u001b[0m loss: 1.213169  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72714)\u001b[0m loss: 1.234326  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104677, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104677, ip=128.55.69.178)\u001b[0m  Accuracy: 58.5%, Avg loss: 1.154764 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104677, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104676, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104676, ip=128.55.69.178)\u001b[0m  Accuracy: 55.4%, Avg loss: 1.228034 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104676, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104675, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104675, ip=128.55.69.178)\u001b[0m  Accuracy: 55.0%, Avg loss: 1.284872 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104675, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104674, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104674, ip=128.55.69.178)\u001b[0m  Accuracy: 57.7%, Avg loss: 1.193321 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104674, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72718)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72718)\u001b[0m  Accuracy: 56.1%, Avg loss: 1.250543 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72718)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72717)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72717)\u001b[0m  Accuracy: 59.0%, Avg loss: 1.144966 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72717)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72716)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72716)\u001b[0m  Accuracy: 56.0%, Avg loss: 1.214283 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72716)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72714)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72714)\u001b[0m  Accuracy: 58.4%, Avg loss: 1.182073 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72714)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104677, ip=128.55.69.178)\u001b[0m loss: 1.293196  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104676, ip=128.55.69.178)\u001b[0m loss: 1.285758  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104675, ip=128.55.69.178)\u001b[0m loss: 1.173951  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=104674, ip=128.55.69.178)\u001b[0m loss: 1.138284  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.503854036331177\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900335\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-25-35\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.182073312997818\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 72529\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.291667461395264\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.291667461395264\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 58.759873151779175\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900335\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.5081298351287842\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72718)\u001b[0m loss: 1.169808  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72717)\u001b[0m loss: 1.332387  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72716)\u001b[0m loss: 1.170479  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=72714)\u001b[0m loss: 1.233121  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=73697)\u001b[0m 2023-03-03 19:25:39,220\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00003_3_lr=0.1000_2023-03-03_19-22-02/checkpoint_tmp259468\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=73697)\u001b[0m 2023-03-03 19:25:39,220\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 2, '_timesteps_total': None, '_time_total': 38.46820569038391, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73846)\u001b[0m 2023-03-03 19:25:41,755\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73846)\u001b[0m 2023-03-03 19:25:45,195\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105143, ip=128.55.69.178)\u001b[0m 2023-03-03 19:25:45,235\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:3\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73846)\u001b[0m 2023-03-03 19:25:46,777\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105143, ip=128.55.69.178)\u001b[0m 2023-03-03 19:25:46,825\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105144, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105146, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73846)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73847)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105143, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105145, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73849)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73848)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73847)\u001b[0m loss: 1.261367  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73849)\u001b[0m loss: 1.346612  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73848)\u001b[0m loss: 1.294568  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73846)\u001b[0m loss: 1.314752  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105144, ip=128.55.69.178)\u001b[0m loss: 1.303506  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105143, ip=128.55.69.178)\u001b[0m loss: 1.306805  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105145, ip=128.55.69.178)\u001b[0m loss: 1.348620  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105146, ip=128.55.69.178)\u001b[0m loss: 1.375405  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73847)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73847)\u001b[0m  Accuracy: 55.6%, Avg loss: 1.242810 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73847)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73849)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73849)\u001b[0m  Accuracy: 57.6%, Avg loss: 1.174410 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73849)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73848)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73848)\u001b[0m  Accuracy: 56.4%, Avg loss: 1.239774 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73848)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73846)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73846)\u001b[0m  Accuracy: 57.7%, Avg loss: 1.207383 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73846)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105144, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105144, ip=128.55.69.178)\u001b[0m  Accuracy: 56.2%, Avg loss: 1.241903 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105144, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105143, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105143, ip=128.55.69.178)\u001b[0m  Accuracy: 57.4%, Avg loss: 1.198868 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105143, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105145, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105145, ip=128.55.69.178)\u001b[0m  Accuracy: 55.4%, Avg loss: 1.220927 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105145, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105146, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105146, ip=128.55.69.178)\u001b[0m  Accuracy: 58.2%, Avg loss: 1.164598 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105146, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.462810516357422\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900359\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-25-59\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.2073830008506774\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 73697\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.13873600959778\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.13873600959778\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 58.60694169998169\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900359\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 3\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.296215295791626\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73847)\u001b[0m loss: 1.141053  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73849)\u001b[0m loss: 1.229499  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73848)\u001b[0m loss: 1.267012  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=73846)\u001b[0m loss: 1.172962  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105144, ip=128.55.69.178)\u001b[0m loss: 1.125151  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105143, ip=128.55.69.178)\u001b[0m loss: 1.184851  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105145, ip=128.55.69.178)\u001b[0m loss: 1.220998  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105146, ip=128.55.69.178)\u001b[0m loss: 1.254001  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=105642, ip=128.55.69.178)\u001b[0m 2023-03-03 19:26:02,316\tINFO trainable.py:791 -- Restored on 10.249.19.154 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00000_0_lr=0.0010_2023-03-03_19-20-49/checkpoint_tmpaf2927\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=105642, ip=128.55.69.178)\u001b[0m 2023-03-03 19:26:02,316\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 58.79319167137146, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105742, ip=128.55.69.178)\u001b[0m 2023-03-03 19:26:05,119\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105742, ip=128.55.69.178)\u001b[0m 2023-03-03 19:26:08,481\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74922)\u001b[0m 2023-03-03 19:26:08,494\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105742, ip=128.55.69.178)\u001b[0m 2023-03-03 19:26:09,989\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74922)\u001b[0m 2023-03-03 19:26:10,018\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105742, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74924)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105743, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105745, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74923)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74922)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105744, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74925)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74922)\u001b[0m loss: 1.349034  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74924)\u001b[0m loss: 1.310535  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74925)\u001b[0m loss: 1.201815  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74923)\u001b[0m loss: 1.107988  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105743, ip=128.55.69.178)\u001b[0m loss: 1.163990  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105742, ip=128.55.69.178)\u001b[0m loss: 1.167238  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105745, ip=128.55.69.178)\u001b[0m loss: 1.297178  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105744, ip=128.55.69.178)\u001b[0m loss: 1.176399  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74922)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74922)\u001b[0m  Accuracy: 64.0%, Avg loss: 1.027654 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74922)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74924)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74924)\u001b[0m  Accuracy: 65.2%, Avg loss: 0.986211 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74925)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74925)\u001b[0m  Accuracy: 62.0%, Avg loss: 1.046212 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74925)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74923)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74923)\u001b[0m  Accuracy: 62.6%, Avg loss: 1.062517 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74923)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105743, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105743, ip=128.55.69.178)\u001b[0m  Accuracy: 61.2%, Avg loss: 1.060416 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105743, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105742, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105742, ip=128.55.69.178)\u001b[0m  Accuracy: 63.8%, Avg loss: 1.043841 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105742, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105745, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105745, ip=128.55.69.178)\u001b[0m  Accuracy: 64.4%, Avg loss: 0.999285 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105745, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105744, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105744, ip=128.55.69.178)\u001b[0m  Accuracy: 62.7%, Avg loss: 1.055367 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105744, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.458876848220825\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900382\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-26-22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.0438405573368073\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: 10.249.19.154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 105642\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.338318586349487\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.338318586349487\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 79.13151025772095\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900382\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.30715131759643555\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74922)\u001b[0m loss: 1.096494  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74924)\u001b[0m loss: 1.126902  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74925)\u001b[0m loss: 1.038184  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=74923)\u001b[0m loss: 1.006380  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105743, ip=128.55.69.178)\u001b[0m loss: 1.033527  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105742, ip=128.55.69.178)\u001b[0m loss: 1.146638  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105745, ip=128.55.69.178)\u001b[0m loss: 1.093009  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=105744, ip=128.55.69.178)\u001b[0m loss: 1.020732  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:26:23,772\tWARNING util.py:244 -- The `process_trial_save` operation took 1.021 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=75785)\u001b[0m 2023-03-03 19:26:27,498\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00001_1_lr=0.0100_2023-03-03_19-21-18/checkpoint_tmpf6c962\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=75785)\u001b[0m 2023-03-03 19:26:27,498\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 58.453394174575806, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75931)\u001b[0m 2023-03-03 19:26:30,443\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106324, ip=128.55.69.178)\u001b[0m 2023-03-03 19:26:33,880\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75931)\u001b[0m 2023-03-03 19:26:33,880\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106324, ip=128.55.69.178)\u001b[0m 2023-03-03 19:26:35,464\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75931)\u001b[0m 2023-03-03 19:26:35,529\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106326, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75932)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75933)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75931)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106325, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106324, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106327, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75934)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75934)\u001b[0m loss: 1.496544  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75933)\u001b[0m loss: 1.306821  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75932)\u001b[0m loss: 1.372525  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75931)\u001b[0m loss: 1.321198  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106326, ip=128.55.69.178)\u001b[0m loss: 1.311828  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106327, ip=128.55.69.178)\u001b[0m loss: 1.438272  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106325, ip=128.55.69.178)\u001b[0m loss: 1.537282  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106324, ip=128.55.69.178)\u001b[0m loss: 1.385873  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75934)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75934)\u001b[0m  Accuracy: 52.5%, Avg loss: 1.275836 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75934)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75933)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75933)\u001b[0m  Accuracy: 51.7%, Avg loss: 1.347075 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75933)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75932)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75932)\u001b[0m  Accuracy: 52.4%, Avg loss: 1.303687 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75932)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75931)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75931)\u001b[0m  Accuracy: 54.9%, Avg loss: 1.271376 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=75931)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106326, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106326, ip=128.55.69.178)\u001b[0m  Accuracy: 49.8%, Avg loss: 1.338405 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106326, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106327, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106327, ip=128.55.69.178)\u001b[0m  Accuracy: 53.0%, Avg loss: 1.268096 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106327, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106325, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106325, ip=128.55.69.178)\u001b[0m  Accuracy: 51.0%, Avg loss: 1.332863 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106325, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106324, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106324, ip=128.55.69.178)\u001b[0m  Accuracy: 53.0%, Avg loss: 1.318563 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106324, ip=128.55.69.178)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:26:47,897\tINFO pbt.py:804 -- \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m [PopulationBasedTraining] [Exploit] Cloning trial 8f5ae_00000 (score = -1.043841) into trial 8f5ae_00001 (score = -1.271376)\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:26:47,897\tINFO pbt.py:831 -- \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m [PopulationBasedTraining] [Explore] Perturbed the hyperparameter config of trial8f5ae_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m train_loop_config : \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m     lr : 0.06 --- (* 1.2) --> 0.072\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m     momentum : 0.9 --- (resample) --> 0.9\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.301666021347046\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900407\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-26-47\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: 6a7c912915ea446c99c8693563996683\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.271375799179077\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 75785\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.396260023117065\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.396260023117065\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 78.84965419769287\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900407\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.2905704975128174\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=76751)\u001b[0m 2023-03-03 19:26:51,221\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00002_2_lr=0.0500_2023-03-03_19-21-40/checkpoint_tmp55a02f\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=76751)\u001b[0m 2023-03-03 19:26:51,221\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 58.759873151779175, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76922)\u001b[0m 2023-03-03 19:26:53,689\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76922)\u001b[0m 2023-03-03 19:26:57,225\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106833, ip=128.55.69.178)\u001b[0m 2023-03-03 19:26:57,244\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76922)\u001b[0m 2023-03-03 19:26:58,771\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106833, ip=128.55.69.178)\u001b[0m 2023-03-03 19:26:58,764\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106834, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76924)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76925)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106833, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76922)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106836, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106835, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76923)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76923)\u001b[0m loss: 1.227200  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76922)\u001b[0m loss: 1.102683  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76925)\u001b[0m loss: 1.293283  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76924)\u001b[0m loss: 1.176510  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106836, ip=128.55.69.178)\u001b[0m loss: 1.200783  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106835, ip=128.55.69.178)\u001b[0m loss: 1.231960  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106834, ip=128.55.69.178)\u001b[0m loss: 1.215915  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106833, ip=128.55.69.178)\u001b[0m loss: 1.138114  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106835, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106835, ip=128.55.69.178)\u001b[0m  Accuracy: 58.2%, Avg loss: 1.176037 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106835, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106834, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106834, ip=128.55.69.178)\u001b[0m  Accuracy: 58.9%, Avg loss: 1.154587 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106834, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106833, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106833, ip=128.55.69.178)\u001b[0m  Accuracy: 59.4%, Avg loss: 1.147546 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106833, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76923)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76923)\u001b[0m  Accuracy: 57.8%, Avg loss: 1.170252 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76923)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76922)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76922)\u001b[0m  Accuracy: 61.6%, Avg loss: 1.109842 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76922)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76925)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76925)\u001b[0m  Accuracy: 61.3%, Avg loss: 1.093218 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76925)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76924)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76924)\u001b[0m  Accuracy: 58.1%, Avg loss: 1.197037 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76924)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106836, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106836, ip=128.55.69.178)\u001b[0m  Accuracy: 61.0%, Avg loss: 1.088818 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106836, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.54538106918335\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900431\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-27-11\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.1098419547080993\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 76751\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.246085166931152\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.246085166931152\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 79.00595831871033\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900431\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.3003509044647217\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76923)\u001b[0m loss: 1.040140  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76922)\u001b[0m loss: 1.177219  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76925)\u001b[0m loss: 1.121406  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=76924)\u001b[0m loss: 1.151621  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106836, ip=128.55.69.178)\u001b[0m loss: 1.176645  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106835, ip=128.55.69.178)\u001b[0m loss: 1.125874  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106834, ip=128.55.69.178)\u001b[0m loss: 1.226347  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=106833, ip=128.55.69.178)\u001b[0m loss: 1.126477  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=107303, ip=128.55.69.178)\u001b[0m 2023-03-03 19:27:14,878\tINFO trainable.py:791 -- Restored on 10.249.19.154 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00003_3_lr=0.1000_2023-03-03_19-22-02/checkpoint_tmpd44d41\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=107303, ip=128.55.69.178)\u001b[0m 2023-03-03 19:27:14,878\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 3, '_timesteps_total': None, '_time_total': 58.60694169998169, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107400, ip=128.55.69.178)\u001b[0m 2023-03-03 19:27:17,763\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107400, ip=128.55.69.178)\u001b[0m 2023-03-03 19:27:21,092\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77813)\u001b[0m 2023-03-03 19:27:21,168\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:0\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77813)\u001b[0m 2023-03-03 19:27:22,696\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107400, ip=128.55.69.178)\u001b[0m 2023-03-03 19:27:22,749\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107400, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107401, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77815)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77813)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77814)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107402, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77816)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107403, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107403, ip=128.55.69.178)\u001b[0m loss: 1.278616  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107402, ip=128.55.69.178)\u001b[0m loss: 1.252916  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107401, ip=128.55.69.178)\u001b[0m loss: 1.092820  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107400, ip=128.55.69.178)\u001b[0m loss: 1.235916  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77814)\u001b[0m loss: 1.186045  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77816)\u001b[0m loss: 1.189643  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77815)\u001b[0m loss: 1.200812  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77813)\u001b[0m loss: 1.209644  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77814)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77814)\u001b[0m  Accuracy: 58.6%, Avg loss: 1.179719 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77814)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77816)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77816)\u001b[0m  Accuracy: 61.8%, Avg loss: 1.087441 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77816)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77815)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77815)\u001b[0m  Accuracy: 59.4%, Avg loss: 1.140469 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77815)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77813)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77813)\u001b[0m  Accuracy: 58.9%, Avg loss: 1.143171 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77813)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107403, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107403, ip=128.55.69.178)\u001b[0m  Accuracy: 61.0%, Avg loss: 1.107376 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107403, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107402, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107402, ip=128.55.69.178)\u001b[0m  Accuracy: 59.3%, Avg loss: 1.167424 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107402, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107401, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107401, ip=128.55.69.178)\u001b[0m  Accuracy: 58.9%, Avg loss: 1.180538 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107401, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107400, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107400, ip=128.55.69.178)\u001b[0m  Accuracy: 62.6%, Avg loss: 1.124766 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107400, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.428468227386475\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900455\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-27-35\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: false\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.1247664749622346\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: 10.249.19.154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 107303\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.40924835205078\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.40924835205078\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 79.01619005203247\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900455\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 4\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.3367307186126709\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107403, ip=128.55.69.178)\u001b[0m loss: 1.228002  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107402, ip=128.55.69.178)\u001b[0m loss: 1.172107  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107401, ip=128.55.69.178)\u001b[0m loss: 1.107329  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107400, ip=128.55.69.178)\u001b[0m loss: 1.122055  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77814)\u001b[0m loss: 1.076064  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77816)\u001b[0m loss: 1.154047  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77815)\u001b[0m loss: 1.152996  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=77813)\u001b[0m loss: 1.148800  [    0/ 6250]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:27:36,329\tWARNING util.py:244 -- The `process_trial_save` operation took 1.035 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=78729)\u001b[0m 2023-03-03 19:27:39,299\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00000_0_lr=0.0010_2023-03-03_19-20-49/checkpoint_tmp77ebb4\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=78729)\u001b[0m 2023-03-03 19:27:39,299\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 4, '_timesteps_total': None, '_time_total': 79.13151025772095, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78867)\u001b[0m 2023-03-03 19:27:41,820\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78867)\u001b[0m 2023-03-03 19:27:45,178\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107977, ip=128.55.69.178)\u001b[0m 2023-03-03 19:27:45,126\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107977, ip=128.55.69.178)\u001b[0m 2023-03-03 19:27:46,684\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78867)\u001b[0m 2023-03-03 19:27:46,778\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107977, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78869)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107978, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78867)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78870)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107980, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78868)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107979, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107979, ip=128.55.69.178)\u001b[0m loss: 1.043445  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107980, ip=128.55.69.178)\u001b[0m loss: 0.997631  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107978, ip=128.55.69.178)\u001b[0m loss: 1.033666  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107977, ip=128.55.69.178)\u001b[0m loss: 1.073080  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78870)\u001b[0m loss: 1.130242  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78869)\u001b[0m loss: 1.002480  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78868)\u001b[0m loss: 0.985551  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78867)\u001b[0m loss: 1.093291  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107979, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107979, ip=128.55.69.178)\u001b[0m  Accuracy: 66.6%, Avg loss: 0.968117 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107979, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107978, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107978, ip=128.55.69.178)\u001b[0m  Accuracy: 63.0%, Avg loss: 1.053709 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107978, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107977, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107977, ip=128.55.69.178)\u001b[0m  Accuracy: 63.9%, Avg loss: 1.028713 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107977, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78870)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78870)\u001b[0m  Accuracy: 66.4%, Avg loss: 0.963801 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78870)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78869)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78869)\u001b[0m  Accuracy: 61.5%, Avg loss: 1.054016 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78869)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78868)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78868)\u001b[0m  Accuracy: 63.6%, Avg loss: 1.043679 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78868)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78867)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78867)\u001b[0m  Accuracy: 66.6%, Avg loss: 0.985433 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=78867)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107980, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107980, ip=128.55.69.178)\u001b[0m  Accuracy: 64.8%, Avg loss: 0.983048 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=107980, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00000:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.428494215011597\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900479\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-27-59\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 0.9854333639144898\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 78729\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.001125812530518\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.001125812530518\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 99.13263607025146\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900479\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00000\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.3280794620513916\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Trial TorchTrainer_8f5ae_00000 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=108482, ip=128.55.69.178)\u001b[0m 2023-03-03 19:28:02,278\tINFO trainable.py:791 -- Restored on 10.249.19.154 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00001_1_lr=0.0100_2023-03-03_19-21-18/checkpoint_tmp7b9bc9\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=108482, ip=128.55.69.178)\u001b[0m 2023-03-03 19:28:02,278\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 4, '_timesteps_total': None, '_time_total': 79.13151025772095, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108581, ip=128.55.69.178)\u001b[0m 2023-03-03 19:28:04,784\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108581, ip=128.55.69.178)\u001b[0m 2023-03-03 19:28:08,187\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79770)\u001b[0m 2023-03-03 19:28:08,197\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108581, ip=128.55.69.178)\u001b[0m 2023-03-03 19:28:09,839\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79770)\u001b[0m 2023-03-03 19:28:09,814\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108584, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79771)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108583, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79774)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108582, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79770)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79772)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108581, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79770)\u001b[0m loss: 1.079005  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79774)\u001b[0m loss: 1.201817  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79771)\u001b[0m loss: 1.013621  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79772)\u001b[0m loss: 0.977002  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108584, ip=128.55.69.178)\u001b[0m loss: 1.130040  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108583, ip=128.55.69.178)\u001b[0m loss: 1.053382  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108582, ip=128.55.69.178)\u001b[0m loss: 1.184199  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108581, ip=128.55.69.178)\u001b[0m loss: 1.088821  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108584, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108584, ip=128.55.69.178)\u001b[0m  Accuracy: 65.5%, Avg loss: 1.012342 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108584, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108583, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108583, ip=128.55.69.178)\u001b[0m  Accuracy: 62.9%, Avg loss: 1.043845 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108583, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108582, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108582, ip=128.55.69.178)\u001b[0m  Accuracy: 61.7%, Avg loss: 1.064778 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108582, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108581, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108581, ip=128.55.69.178)\u001b[0m  Accuracy: 66.2%, Avg loss: 1.010938 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=108581, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79770)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79770)\u001b[0m  Accuracy: 62.6%, Avg loss: 1.030255 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79770)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79774)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79774)\u001b[0m  Accuracy: 64.6%, Avg loss: 0.986289 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79774)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79771)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79771)\u001b[0m  Accuracy: 63.8%, Avg loss: 1.069141 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79771)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79772)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79772)\u001b[0m  Accuracy: 64.2%, Avg loss: 1.028239 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=79772)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00001:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.343645572662354\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900502\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-28-22\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003045\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.0109383702278136\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: 10.249.19.154\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 108482\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.00830578804016\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.00830578804016\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 99.13981604576111\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900502\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00001\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.30339956283569336\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Trial TorchTrainer_8f5ae_00001 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:28:23,260\tWARNING util.py:244 -- The `process_trial_save` operation took 0.967 s, which may be a performance bottleneck.\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=80619)\u001b[0m 2023-03-03 19:28:27,252\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00002_2_lr=0.0500_2023-03-03_19-21-40/checkpoint_tmpf40f8a\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=80619)\u001b[0m 2023-03-03 19:28:27,252\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 4, '_timesteps_total': None, '_time_total': 79.00595831871033, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80753)\u001b[0m 2023-03-03 19:28:29,786\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80753)\u001b[0m 2023-03-03 19:28:33,048\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:2\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109245, ip=128.55.69.178)\u001b[0m 2023-03-03 19:28:33,058\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:2\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109245, ip=128.55.69.178)\u001b[0m 2023-03-03 19:28:34,578\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80753)\u001b[0m 2023-03-03 19:28:34,697\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109245, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109247, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80756)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80754)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80753)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80755)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109248, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109246, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109245, ip=128.55.69.178)\u001b[0m loss: 1.069553  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109248, ip=128.55.69.178)\u001b[0m loss: 1.230193  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109247, ip=128.55.69.178)\u001b[0m loss: 1.148094  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109246, ip=128.55.69.178)\u001b[0m loss: 1.196400  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80756)\u001b[0m loss: 1.185359  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80755)\u001b[0m loss: 1.112800  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80754)\u001b[0m loss: 1.141431  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80753)\u001b[0m loss: 1.184870  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109245, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109245, ip=128.55.69.178)\u001b[0m  Accuracy: 64.2%, Avg loss: 1.037805 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109245, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109248, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109248, ip=128.55.69.178)\u001b[0m  Accuracy: 64.3%, Avg loss: 0.972038 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109248, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109247, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109247, ip=128.55.69.178)\u001b[0m  Accuracy: 63.4%, Avg loss: 1.049293 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109247, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109246, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109246, ip=128.55.69.178)\u001b[0m  Accuracy: 62.2%, Avg loss: 1.080602 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109246, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80756)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80756)\u001b[0m  Accuracy: 62.3%, Avg loss: 1.031951 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80756)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80755)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80755)\u001b[0m  Accuracy: 61.0%, Avg loss: 1.088412 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80755)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80754)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80754)\u001b[0m  Accuracy: 62.5%, Avg loss: 1.056462 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80754)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80753)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80753)\u001b[0m  Accuracy: 64.0%, Avg loss: 1.004145 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=80753)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00002:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.446613311767578\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900526\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-28-47\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.0041450023651124\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 80619\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.00997018814087\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.00997018814087\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 99.0159285068512\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900527\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00002\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.3047199249267578\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Trial TorchTrainer_8f5ae_00002 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TorchTrainer pid=81595)\u001b[0m 2023-03-03 19:28:50,685\tINFO trainable.py:791 -- Restored on nid003044 from checkpoint: /global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00003_3_lr=0.1000_2023-03-03_19-22-02/checkpoint_tmpba0165\n",
      "\u001b[2m\u001b[36m(TorchTrainer pid=81595)\u001b[0m 2023-03-03 19:28:50,686\tINFO trainable.py:800 -- Current state after restoring: {'_iteration': 4, '_timesteps_total': None, '_time_total': 79.01619005203247, '_episodes_total': None}\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81741)\u001b[0m 2023-03-03 19:28:53,614\tINFO config.py:86 -- Setting up process group for: env:// [rank=0, world_size=8]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81741)\u001b[0m 2023-03-03 19:28:57,087\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109753, ip=128.55.69.178)\u001b[0m 2023-03-03 19:28:57,067\tINFO train_loop_utils.py:255 -- Moving model to device: cuda:1\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109753, ip=128.55.69.178)\u001b[0m 2023-03-03 19:28:58,582\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81741)\u001b[0m 2023-03-03 19:28:58,658\tINFO train_loop_utils.py:315 -- Wrapping provided model in DistributedDataParallel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109754, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109753, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109755, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81743)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81741)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81742)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81744)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109756, ip=128.55.69.178)\u001b[0m Files already downloaded and verified\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109754, ip=128.55.69.178)\u001b[0m loss: 1.128427  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109753, ip=128.55.69.178)\u001b[0m loss: 1.078292  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109755, ip=128.55.69.178)\u001b[0m loss: 1.117896  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109756, ip=128.55.69.178)\u001b[0m loss: 1.147443  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81741)\u001b[0m loss: 1.113449  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81744)\u001b[0m loss: 1.137184  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81742)\u001b[0m loss: 1.130889  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81743)\u001b[0m loss: 1.110579  [    0/ 6250]\n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81741)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81741)\u001b[0m  Accuracy: 62.2%, Avg loss: 1.048268 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81741)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81744)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81744)\u001b[0m  Accuracy: 63.0%, Avg loss: 1.032168 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81744)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81742)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81742)\u001b[0m  Accuracy: 62.2%, Avg loss: 1.087330 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81742)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81743)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81743)\u001b[0m  Accuracy: 60.7%, Avg loss: 1.079074 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=81743)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109754, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109754, ip=128.55.69.178)\u001b[0m  Accuracy: 62.0%, Avg loss: 1.083989 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109754, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109753, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109753, ip=128.55.69.178)\u001b[0m  Accuracy: 62.7%, Avg loss: 1.039499 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109753, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109755, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109755, ip=128.55.69.178)\u001b[0m  Accuracy: 61.4%, Avg loss: 1.060204 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109755, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109756, ip=128.55.69.178)\u001b[0m Test Error: \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109756, ip=128.55.69.178)\u001b[0m  Accuracy: 65.7%, Avg loss: 0.995797 \n",
      "\u001b[2m\u001b[36m(RayTrainWorker pid=109756, ip=128.55.69.178)\u001b[0m \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Result for TorchTrainer_8f5ae_00003:\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _time_this_iter_s: 15.30578351020813\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _timestamp: 1677900550\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   _training_iteration: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   date: 2023-03-03_19-29-11\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   done: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   experiment_id: d885e70a346b4e1da22b85382d44f281\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   hostname: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   iterations_since_restore: 1\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   loss: 1.0482683598995208\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   node_ip: nid003044\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   pid: 81595\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   should_checkpoint: true\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_since_restore: 20.42299723625183\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_this_iter_s: 20.42299723625183\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   time_total_s: 99.4391872882843\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timestamp: 1677900551\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   timesteps_since_restore: 0\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   training_iteration: 5\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   trial_id: 8f5ae_00003\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   warmup_time: 0.32995128631591797\n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m   \n",
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m Trial TorchTrainer_8f5ae_00003 completed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(TunerInternal pid=61223)\u001b[0m 2023-03-03 19:29:11,126\tINFO tune.py:798 -- Total run time: 502.20 seconds (502.13 seconds for the tuning loop).\n"
     ]
    }
   ],
   "source": [
    "results = tuner.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0e3df6ee-bf06-49c8-8f86-764e19183237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result(metrics={'loss': 0.9854333639144898, '_timestamp': 1677900479, '_time_this_iter_s': 15.428494215011597, '_training_iteration': 1, 'should_checkpoint': True, 'done': True, 'trial_id': '8f5ae_00000', 'experiment_tag': '0_lr=0.0010@perturbed[train_loop_config=lr_0_06_momentum_0_9_batch_size_1024_test_mode_False_data_dir_pscratch_sd_a_asnaylor_CIFAR10_epochs_5]'}, error=None, log_dir=PosixPath('/global/homes/a/asnaylor/ray_results/TorchTrainer_2023-03-03_19-20-47/TorchTrainer_8f5ae_00000_0_lr=0.0010_2023-03-03_19-20-49'))\n"
     ]
    }
   ],
   "source": [
    "print(results.get_best_result(metric=\"loss\", mode=\"min\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef56f4d5-6936-46f4-991a-dcc6ba2e3db6",
   "metadata": {},
   "source": [
    "## Close cluster conection and stop job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0ea45984-c437-4407-a610-9eb4be8b5721",
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ac4d0fcd-5e09-484e-8aad-3fa35e3442ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task_id': '0', 'status': 'OK', 'error': None}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sfp_api.delete_job(site, job['jobid'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34c966d1-1723-4ccb-859d-1159e64092fd",
   "metadata": {},
   "source": [
    "## Explore Training in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "57187648-aff0-4ba7-8ead-76aea7e32307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import nersc_tensorboard_helper\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3337f2bf-3caf-4c65-b04b-5caa6bdf1313",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = str(results.get_best_result(metric=\"loss\", mode=\"min\").log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "93ff457f-3939-4ee4-a25b-38d994875801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-6078813707907a89\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-6078813707907a89\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 37893;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir $log_dir --port 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d31f89a-c525-457a-b65f-ec90ac5d4693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"https://jupyter.nersc.gov/user/asnaylor/perlmutter-shared-node-cpu/proxy/37893/\">https://jupyter.nersc.gov/user/asnaylor/perlmutter-shared-node-cpu/proxy/37893/</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nersc_tensorboard_helper.tb_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff244be-78af-4a2d-a54f-6d684c38f6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc9a3b-d563-4fc8-8c15-01ffbe3b12e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-1.13.1",
   "language": "python",
   "name": "pytorch1.13.1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
